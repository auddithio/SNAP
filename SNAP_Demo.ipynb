{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/chung-neuroai-lab/SNAP/blob/main/SNAP_Demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to install the code and dependencies. This might not be necessary if you cloned the repo locally, but it is helpful for colab. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1698455585909,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "0BPKlQp6Tk3t",
    "outputId": "74c0a547-4e8f-4baa-9f17-aa6c16c2c6f9"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/chung-neuroai-lab/SNAP\n",
    "# Brainscore is installed separately from setup.py because of some conflicting dependencies\n",
    "!pip install git+https://github.com/brain-score/brainio.git\n",
    "!pip install git+https://github.com/brain-score/result_caching\n",
    "!pip install --no-deps git+https://github.com/brain-score/brain-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setting some paths for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1698455588913,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "mEPX8h8PTk3u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from itertools import product\n",
    "\n",
    "from snap.wrapper import TorchWrapper\n",
    "from snap.experiment import Experiment\n",
    "from snap.brainscore_data import get_neural_data\n",
    "from snap.regression_utils import regression_metric\n",
    "import snap.models as models\n",
    "from snap.data_utils import DataProcess\n",
    "from snap import figure_utils\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "data_root = 'data/'\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ns0e3FaCTk3u"
   },
   "source": [
    "## Run the analysis computing the theoretical and empirical generalization error, and measures for error mode geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1698455639531,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "mHkTmLxM1lsZ"
   },
   "outputs": [],
   "source": [
    "# Model list to analyze -- code can be RAM intensive so choosing\n",
    "# a small model here for demo.\n",
    "modelNames = ['cornet',\n",
    "              ]\n",
    "\n",
    "# These are the 4 regions analyzed from the Brain-Score datasets.\n",
    "# Only analyzing V1 and V2 in demo for speed and compute.\n",
    "regionNames = ['V1',\n",
    "               'V2',\n",
    "                'V4',\n",
    "                'IT'\n",
    "               ]\n",
    "\n",
    "# Options are available for pooling the activations after extracting them.\n",
    "# In the 2023 NeurIPS paper main text experiments we use the full activations.\n",
    "activation_pooling = [None,\n",
    "                         'MaxPool_(1,1)',\n",
    "                         'AvgPool_(1,1)',\n",
    "                      ]\n",
    "\n",
    "# Option for subsampling activations by randomly projecting the data\n",
    "# In the 2023 NeurIPS paper we use the full activations.\n",
    "rand_proj_dim = None\n",
    "\n",
    "pretrained = {True: 'pretrained',\n",
    "              False: 'untrained'\n",
    "              }\n",
    "\n",
    "# Pytorch arguments for loading the dataset.\n",
    "loader_kwargs = {'batch_size': 200,\n",
    "                 'shuffle': False,\n",
    "                 'num_workers': 2,\n",
    "                 'pin_memory': True,\n",
    "                 'onehot': True,\n",
    "                 'labels_from': 'neural_activity'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127116,
     "status": "ok",
     "timestamp": 1698455768034,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "33qDJHYYTk3v",
    "outputId": "ea5c4b46-a459-413d-9748-687adbaa6751",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through the analyses specified above.\n",
    "for region in regionNames:\n",
    "    data_loader_neural, images, labels = get_neural_data(region=region,\n",
    "                                            loader_kwargs=loader_kwargs)\n",
    "    for model_name in modelNames:\n",
    "        for pooling in activation_pooling:\n",
    "            for trained in [True, False]:\n",
    "                data_dir = os.path.join(data_root,\n",
    "                    f\"data_{pooling}_RandProj_{rand_proj_dim}\")\n",
    "                data_fname = os.path.join(data_dir,\n",
    "                    f\"{region}_data_{model_name}_{pretrained[trained]}.npz\")\n",
    "                os.makedirs(data_dir, exist_ok=True)\n",
    "                print(data_fname)\n",
    "\n",
    "                # Get the model\n",
    "                model_kwargs = {'name': model_name,\n",
    "                                'pretrained': trained,\n",
    "                                'device': device}\n",
    "                model, layers, identifier = models.get_model(**model_kwargs)\n",
    "                model_wrapped = TorchWrapper(model,\n",
    "                                             layers=layers,\n",
    "                                             identifier=identifier,\n",
    "                                             activation_pooling=pooling)\n",
    "\n",
    "                # Create the Experiment Class and pass additional metrics\n",
    "                regression_kwargs = {'num_trials': 5,\n",
    "                                     'reg': 1e-14,\n",
    "                                     'num_points': 5,\n",
    "                                     }\n",
    "\n",
    "                metric_fns = [regression_metric]\n",
    "                exp = Experiment(model_wrapped,\n",
    "                                 metric_fns=metric_fns,\n",
    "                                 rand_proj_dim=rand_proj_dim)\n",
    "\n",
    "                # Extract the activations of the layers passed above\n",
    "                # using data_loader (only uses the inputs)\n",
    "                exp.get_activations(data_loader_neural())\n",
    "\n",
    "                # Compute metrics\n",
    "                metric_kwargs = {'debug': False,\n",
    "                                 'epsilon': 1e-14\n",
    "                                 } | regression_kwargs\n",
    "\n",
    "                exp_metrics = exp.compute_metrics(images=images,\n",
    "                                                  labels=labels,\n",
    "                                                  **metric_kwargs)\n",
    "                layers = exp_metrics['layers']\n",
    "\n",
    "                # Save all of the metrics so we can load them.\n",
    "                np.savez(data_fname, exp_metrics=exp_metrics,\n",
    "                         layers=layers, metric_kwargs=metric_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDtQlywgqOTy"
   },
   "source": [
    "## Process the data for the individual files\n",
    "\n",
    "Combine the data for the individual experiments analyzed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9421,
     "status": "ok",
     "timestamp": 1698455777443,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "9HtbBU9nTk3v",
    "outputId": "c38cf1c2-4b65-4e07-8a63-d154d27baf93"
   },
   "outputs": [],
   "source": [
    "processed_data_root = os.path.join(data_root, 'processed/')\n",
    "\n",
    "os.makedirs(processed_data_root, exist_ok=True)\n",
    "\n",
    "rand_projections = ['None']\n",
    "activation_pooling = ['None']\n",
    "pooling_list = []\n",
    "for item in product(activation_pooling, rand_projections):\n",
    "    pooling_list += [\"_RandProj_\".join(item)]\n",
    "activation_pooling = pooling_list.copy()\n",
    "\n",
    "Data = DataProcess(data_root,\n",
    "                   activation_pooling,\n",
    "                   regionNames,\n",
    "                   modelNames,\n",
    "                   pretrained)\n",
    "dfs_all = Data.get_dataframe(load=False, save_all_data_pckl=True)\n",
    "\n",
    "sort_coord = 'final_scores'\n",
    "threshold = 0.99\n",
    "\n",
    "region_list = Data.region_list\n",
    "pooling_list = Data.pooling_list\n",
    "model_list = Data.model_list\n",
    "\n",
    "for trained in pretrained.keys():\n",
    "  for region in region_list:\n",
    "      for pooling in pooling_list:\n",
    "          print(region, pooling)\n",
    "          processed_data_name = os.path.join(processed_data_root,\n",
    "                                             f'{region}_{pooling}_{pretrained[trained]}.npz')\n",
    "\n",
    "          all_data_kwargs = dict(sort_coord=sort_coord,\n",
    "                                 trained=trained,\n",
    "                                 region_list=[region],\n",
    "                                 pooling_list=[pooling],\n",
    "                                 model_list=model_list,\n",
    "                                 eff_dim_cutoff=0,\n",
    "                                 threshold=threshold,\n",
    "                                 )\n",
    "          all_reg_hist, all_processed_data = Data.get_all_data(**all_data_kwargs)\n",
    "          all_reg_hist = all_reg_hist[region][pooling]\n",
    "          all_processed_data = all_processed_data[region][pooling]\n",
    "\n",
    "          np.savez(processed_data_name,\n",
    "                   all_reg_hist=all_reg_hist,\n",
    "                   all_processed_data=all_processed_data,\n",
    "                   all_data_kwargs=all_data_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjKGcEu8xtpL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698455777443,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "ewVIymvioKds"
   },
   "source": [
    "## Example Figures\n",
    "\n",
    "Load in the data for the figure plotting and make the theory vs. empirical plot and some example contour plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698455777443,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "6_rsI5eOoQD2"
   },
   "outputs": [],
   "source": [
    "# Only looking at full activations, no random projections\n",
    "activation_pooling = ['None']\n",
    "rand_projections = [\"None\"]\n",
    "pooling = 'None_RandProj_None'\n",
    "p_idx = -5 # Corresponds to 60/40 train/test split\n",
    "\n",
    "(all_reg_hist,\n",
    " all_processed_data,\n",
    " all_data_kwargs) = figure_utils.get_processed_data_figs(region_list,\n",
    "                                                         pooling_list,\n",
    "                                                         trained=True,\n",
    "                                                         )\n",
    "(all_reg_hist_random,\n",
    " all_processed_data_random,\n",
    " all_data_kwargs_random) = figure_utils.get_processed_data_figs(region_list,\n",
    "                                                                pooling_list,\n",
    "                                                                trained=False,\n",
    "                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9qv_ukPycfA"
   },
   "source": [
    "## Theory = Empirical Scatter Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1698455777852,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "7H7fhTNByYRE",
    "outputId": "dfff1d40-ca5f-49a1-ba59-32c63bfdc262"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3.5))\n",
    "\n",
    "for r_idx, region in enumerate(region_list):\n",
    "    plt.subplot(1, 4, r_idx+1)\n",
    "\n",
    "    x_val = []\n",
    "    y_val = []\n",
    "    p_val = []\n",
    "    p_max = []\n",
    "    for model, model_data in all_processed_data[region][pooling].items():\n",
    "        p_val.append(model_data['pvals_mode'][:, p_idx])\n",
    "        p_max.append(model_data['pvals_mode'][:, -1])\n",
    "\n",
    "        x_val.append(model_data['gen_errs'][:, p_idx])\n",
    "\n",
    "        r = model_data['dyn_weight_rads'][:, p_idx]\n",
    "        sqrt_d = model_data['dyn_tads'][:, p_idx]\n",
    "\n",
    "        y_val.append(r * sqrt_d)\n",
    "\n",
    "    x_val = np.concatenate(x_val)\n",
    "    y_val = np.concatenate(y_val)\n",
    "    p_val = np.concatenate(p_val)\n",
    "    p_max = np.concatenate(p_max)\n",
    "\n",
    "    assert (len(np.unique(p_val)) == 1)\n",
    "    assert (len(np.unique(p_max)) == 1)\n",
    "\n",
    "    r = np.corrcoef(x_val, y_val)[0, 1]\n",
    "\n",
    "    plt.scatter(x_val,\n",
    "                y_val,\n",
    "                marker='.',\n",
    "                color='k'\n",
    "                )\n",
    "\n",
    "    p_frac = np.unique(p_val)[0]/np.unique(p_max)[0]\n",
    "    plt.title('%s\\n$R^2$=%0.3f' % (region, r**2))\n",
    "    plt.xlabel('$E_g(p)$, empirical')\n",
    "    plt.ylabel('$E_g(p)$, theoretical')\n",
    "\n",
    "    x_l = plt.xlim()\n",
    "    y_l = plt.ylim()\n",
    "\n",
    "    lims = [min(x_l[0], y_l[0]), max(x_l[1], y_l[1])]\n",
    "    plt.xlim([lims[0], lims[1]])\n",
    "    plt.ylim([lims[0], lims[1]])\n",
    "    plt.plot([lims[0], lims[1]],\n",
    "             [lims[0], lims[1]],\n",
    "             'k--')\n",
    "\n",
    "    print('%s: P = %0.3fp, %s Model-Stages Analyzed' % (region, p_frac, len(x_val)))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour plots coded by the generalization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1698455778840,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "Z_pLhQIGyZT8",
    "outputId": "e240608b-7a0e-4f32-bbde-66ecf0bc03a0"
   },
   "outputs": [],
   "source": [
    "# Good for training data, showing the generalization error\n",
    "cmap_min = 0.2\n",
    "cmap_max = 1.\n",
    "\n",
    "figs, ax = plt.subplots(nrows=1,\n",
    "                        ncols=len(region_list),\n",
    "                        figsize=(len(region_list)*3.5, 3),\n",
    "                        )\n",
    "ax = ax.ravel()\n",
    "\n",
    "_ = figure_utils.plot_region_contours(all_reg_hist, region_list,\n",
    "                                      pooling,\n",
    "                                      p_idx=p_idx,\n",
    "                                      x_lims=None,\n",
    "                                      y_lims=None,\n",
    "                                      coloring='gen_errs',\n",
    "                                      c_map_min=cmap_min,\n",
    "                                      c_map_max=cmap_max,\n",
    "                                      marker_size=5,\n",
    "                                      ax_handle=ax,\n",
    "                                      cmap='Greys_r',\n",
    "                                      save_figures=False,\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour plots coded by the normalized layer-depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1698456515044,
     "user": {
      "displayName": "Jenelle Feather",
      "userId": "09285763609401412430"
     },
     "user_tz": 240
    },
    "id": "sY_U2IRwzCnZ",
    "outputId": "bbdf244d-8700-4cbc-e5f4-115b64d56cfc"
   },
   "outputs": [],
   "source": [
    "figs, ax = plt.subplots(nrows=1,\n",
    "                        ncols=len(region_list),\n",
    "                        figsize=(len(region_list)*3.5, 3),\n",
    "                        )\n",
    "ax = ax.ravel()\n",
    "\n",
    "x_lims_cropped = {'V1': [0.022, 0.055],\n",
    "          'V2': [0.022, 0.055],\n",
    "          'V4': [0.004, 0.012],\n",
    "          'IT': [0.004, 0.012]}\n",
    "\n",
    "y_lims_cropped = {'V1': [8.6, 11.25],\n",
    "          'V2': [8.6, 11.25],\n",
    "          'V4': [38, 50],\n",
    "          'IT': [39, 51.5]}\n",
    "\n",
    "cropped_contour_min_max = [0.2, 0.55]\n",
    "layer_data = figure_utils.plot_region_contours(all_reg_hist, region_list,\n",
    "                                               pooling,\n",
    "                                               p_idx=p_idx,\n",
    "                                               x_lims=x_lims_cropped,\n",
    "                                               y_lims=y_lims_cropped,\n",
    "                                               coloring='layer_depth_normalized',\n",
    "                                               c_map_min_contours=cropped_contour_min_max[0],\n",
    "                                               c_map_max_contours=cropped_contour_min_max[1],\n",
    "                                               cmap=plt.cm.plasma_r,\n",
    "                                               c_bar_label='Layer Depth',\n",
    "                                               marker_size=5,\n",
    "                                               ax_handle=ax,\n",
    "                                               cmap_contours='Greys_r',\n",
    "                                               save_figures=False,\n",
    "                                               )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "646a38c27b25f91c7f2c209818123b42f39f35e324f4a627b8ac987db1a3b2a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
